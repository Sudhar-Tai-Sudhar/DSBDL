{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424843cd-daba-4330-8150-74021454bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "367a45c0-795a-4a25-a245-235bbe409e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bhush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bhush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bhush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\bhush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210da28c-64bd-40f1-8507-a4a827f156f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"Natural Language Processing (NLP) is a sub-field of Artificial Intelligence that focuses on the interaction between computers and humans using natural language.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d155aecd-69e8-4703-8193-39e6fcfa952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'sub-field', 'of', 'Artificial', 'Intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'using', 'natural', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(document)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d924a3-18d8-4a0a-a48d-7d28437a8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('sub-field', 'NN'), ('of', 'IN'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('that', 'WDT'), ('focuses', 'VBZ'), ('on', 'IN'), ('the', 'DT'), ('interaction', 'NN'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('humans', 'NNS'), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = pos_tag(tokens)\n",
    "print(\"POS Tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fad1d74c-7a29-4b28-a682-84e5f3ad3f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'sub-field', 'Artificial', 'Intelligence', 'focuses', 'interaction', 'computers', 'humans', 'using', 'natural', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokens_no_stopwords = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"After Stopword Removal:\", tokens_no_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dca5e7ec-98e0-4720-935c-e79b32bbf088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stemming: ['natur', 'languag', 'process', '(', 'nlp', ')', 'sub-field', 'artifici', 'intellig', 'focus', 'interact', 'comput', 'human', 'use', 'natur', 'languag', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens_no_stopwords]\n",
    "print(\"After Stemming:\", stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb02c3cb-757b-47cd-9597-c5bdd42b4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Lemmatization: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'sub-field', 'Artificial', 'Intelligence', 'focus', 'interaction', 'computer', 'human', 'using', 'natural', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens_no_stopwords]\n",
    "print(\"After Lemmatization:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94f632ba-2f25-4d9c-9ecc-1140c1bcefb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      " [[0.19611614 0.19611614 0.19611614 0.19611614 0.19611614 0.19611614\n",
      "  0.19611614 0.19611614 0.19611614 0.19611614 0.39223227 0.39223227\n",
      "  0.19611614 0.19611614 0.19611614 0.19611614 0.19611614 0.19611614\n",
      "  0.19611614 0.19611614]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([document])\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "851051a3-7a9b-4492-b7eb-c5d400c18768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Names:\n",
      " ['and' 'artificial' 'between' 'computers' 'field' 'focuses' 'humans'\n",
      " 'intelligence' 'interaction' 'is' 'language' 'natural' 'nlp' 'of' 'on'\n",
      " 'processing' 'sub' 'that' 'the' 'using']\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Feature Names:\\n\", tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b4e4c-c401-4250-ac5d-d94853ec0676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
